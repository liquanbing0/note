s3cmd使用手册
## 一、安装
- `yum install s3cmd`

## 二、使用
### 1. 配置方法
- 更改`$HOME/.s3cfg`配置文件
	>`s3cmd --configure`
	>`s3cmd -c FILE`FILE为已完成配置的文件
- 推荐更改项：
	>`access_key = <your access key id>`
	>`secret_key = <your access key secret>`
	>`host_base = host:port`
	>`host_bucket = %(bucket)s.host`
	>`use_https = False #Default is True`

### 2. 操作
1. 创建Bucket，且Bucket名称是唯一的。
	>`s3cmd mb s3://BUCKET`
	>`s3cmd mb s3://my_bucket_name`

2. 删除空Bucket
	>`s3cmd rb s3://BUCKET`
	>`s3cmd rb s3://my_bucket_name`

3. 列举Object或Bucket
	>`s3cmd ls [s3://BUCKET[/PREFIX]]`
	>`s3cmd ls s3://my_bucket_name`
	>`s3cmd ls s3://my_bucket_name/file.txt`

4. 列举所有Buckets
	>`s3cmd ls`

5. 上传Object到某个Bucket
	>`s3cmd put FILE [FILE...] s3://BUCKET[/PREFIX]`
	>上传单个文件
	>`s3cmd put file.txt s3://my_bucket_name/file.txt`
	>批量上传文件（上传当前目录下的所有文件）
	>`s3cmd put ./* s3://my_bucket_name/`
	>递归上传文件（递归上传当前目录下的所有文件）
	>`s3cmd put ./* s3://my_bucket_name/ -r`

**注：**当文件大于`15MB`时，会采用分段上传，可通过与`--multipart-chunk-size-mb=SIZE`联用，设置上传块大小。也可以与`--disable-multipart`联用取消分段上传

6. 从Bucket下载Object
	>`s3cmd get s3://BUCKET/OBJECT LOCAL_FILE`
	>下载单个文件
	>`s3cmd get s3://my_bucket_name/file.txt file.txt`
	>批量下载（下载到当前目录）
	>`s3cmd get s3://my-bucket-name/* ./`


7. 删除Object
	>`s3cmd del s3://BUCKET/OBJECT`或`s3cmd rm s3://BUCKET/OBJECT`
	>`s3cmd del s3://my_bucket_name/file.txt`
	>或`s3cmd rm s3://my_bucket_name/file.txt`
	>`rm`是`del`的别名

8. 从Glacier存储类中恢复文件
	>`s3cmd restore s3://BUCKET/OBJECT`
	>`s3cmd restore s3://my_bucket_name/file.txt`

9. 同步目录树（同步操作是要进行MD5校验的，只有当文件不同时，才会被传输）
	>`s3cmd sync LOCAL_DIR s3://BUCKET[/PREFIX]` 或 `s3://BUCKET[/PREFIX] LOCAL_DIR`
	>同步当前目录下的所有文件：`s3cmd sync  ./  s3://my_bucket_name/`

10.  获取对应的Bucket所占用的空间大小
	>`s3cmd du [s3://BUCKET[/PREFIX]]`
	>`s3cmd du s3://my_bucket_name`得到：
	>179813669 19 objects s3://my_bucket_name/
	>`s3cmd du -H s3://my_bucket_name`得到：
	>171M     19 objects s3://test_bucket01/

11. 获取Bucket或Object的版本信息
	>`s3cmd info s3://BUCKET[/OBJECT]`
	>`s3cmd info s3://my_bucket_name`
	>`s3cmd info s3://my_bucket_name/file.txt`

12. 复制Object（从BUCKET1/OBJECT1复制到BUCKET2[/OBJECT2]）
	>`s3cmd cp s3://BUCKET1/OBJECT1 s3://BUCKET2[/OBJECT2]`
	>`s3cmd cp s3://my_bucket_name1/file1.txt s3://my_bucket_name2/file2.txt`

13. 修改Object元数据
	>`s3cmd modify s3://BUCKET1/OBJECT`
	>修改**example.jpg**的 `--mime-type`为`imge/jpeg`
	>`s3cmd modify --mime-type="image/jpeg" s3://my_bucket01/example.jpg`

14. 移动Object
	>`s3cmd mv s3://BUCKET1/OBJECT1 s3://BUCKET2[/OBJECT2]`
	>`s3cmd mv s3://my_bucket_name1/file1.txt s3://my_bucket_name2/file2.txt`

15. 修改Bucket或对象的ACL
	>`s3cmd setacl s3://BUCKET[/OBJECT]`
	>Bucket和Bucket所有Object权限私有`s3cmd setacl s3://my_bucket_name -acl-private --recursive`
	>Bucket权限私有Object权限不变`s3cmd setacl s3://my_bucket_name -acl-private`

16. 修改Bucket策略
	>`s3cmd setpolicy FILE s3://BUCKET`
	>本地策略policy.json
	```
	{
	"Version": "2012-10-17",
	"Statement": [
		{
		"Sid": "AddPerm",
		"Effect": "Allow",
		"Principal": "*",
		"Action": [
			"s3:GetObject"
		],
		"Resource": [
			"arn:aws:s3:::volpublic/*"
		]
		}
	]
	}
	```
	>设置my_bucket_name的Bucket策略`s3cmd setpolicy policy.json s3://my_bucket_name`

17. 删除Bucket策略
	>`s3cmd delpolicy s3://BUCKET`

18. 修改Bucket CORS
	>`s3cmd setcors FILE s3://BUCKET`

19. 删除Bucket CORS
	>`s3cmd delcors s3://BUCKET`

20. 修改Bucket请求者付费策略
	>`s3cmd payer s3://BUCKET`
	>修改为申请方付款存储桶
	>`s3cmd payer s3://BUCKET --requester-pays`
	>修改为存储桶拥有者付款存储桶
	>`s3cmd payer s3://BUCKET`

21. 显示分段上传
	>`s3cmd multipart s3://BUCKET [Id]`

22. 放弃分段上传
	>`s3cmd abortmp s3://BUCKET/OBJECT Id`

23. 列出分段上传
	>`s3cmd listmp s3://BUCKET/OBJECT Id`

24. 打开/关闭Bucket的access logging
	>`s3cmd accesslog s3://BUCKET`

25. 使用secret key生成签名
	>`s3cmd sign STRING-TO-SIGN`
	>若`secret key`为`"sfdserqwovbnxz2dsc"`
	>`s3cmd sign sfdserqwovbnxz2dsc`得到：
	>`Signature: G3GtIkpMWFiyd/FLVvZ2z76xC20=`

26. 提供有时间期限的公共访问S3的URL
	>`s3cmd signurl s3://BUCKET/OBJECT <expiry_epoch|+expiry_offset>`
	>生成1小时后过期的带有签名的url：
	>`s3cmd signurl s3://test_bucket01/example.jpg +3600`得到：
	>`http://test_bucket01.ceph40:7480/example.jpg?AWSAccessKeyId=ENECX2I210OUE60CE3LF&Expires=1471258746&Signature=AOHcWQlu0tFPJCKqsE6DUmF8sRU%3D`
	>生成24小时后过期的带有签名的url：
	>在未来的时间节点`1471344144`后过期：
	>`s3cmd signurl s3://test_bucket01/example.jpg 1471344144`得到：
	>`http://test_bucket01.ceph40:7480/example.jpg?AWSAccessKeyId=ENECX2I210OUE60CE3LF&Expires=1471344144&Signature=4%2FTlQiqvcPu8tfgCjVwjR%2BdwLDI%3D`

27. 修复Bucket中无效的文件名
	>`s3cmd fixbucket s3://BUCKET[/PREFIX]`

28. 创建Bucket Website
	>`s3cmd ws-create s3://BUCKET`

29. 删除Bucket Website
	>`s3cmd ws-delete s3://BUCKET`

30. 列出Bucket Website信息
	>`s3cmd ws-info s3://BUCKET`

31. 设置或删除Bucket过期规则
	>`s3cmd expire s3://BUCKET`

32. 上传Bucket的生命周期策略
	>`s3cmd setlifecycle FILE s3://BUCKET`

33. 移除Bucket的生命周期策略
	>`s3cmd dellifecycle s3://BUCKET`


### 3.  选项

1. `-h, -help`：查找帮助
2. `--configure`：配置工具
3. `-c FILE, --config=FILE`：配置文件名，默认为`$HOME/.s3cfg`
4. `--dump-config`：解析配置文件后转换为当前的配置
5. `--access_key=ACCESS_KEY`，
   `--secret_key=SECRET_KEY`：设置Access Key和Secret Key
6. `-e, --encrypt`：在上传前加密文件
7. `--no-encrypt `：不加密文件
8. ` -f, --force`：强制覆盖和其他危险性操作
9. `--continue`：继续获取分段下载文件（只适用于`get`操作）
10. `--continue-put`：继续上传部分分段上传文件或分段上传部分
11. `--upload-id=UPLOAD_ID`：当你想继续现有的上传，而使用的分段上传的`UploadId`，可以使用`s3cmd multipart [URI]`命令查看`UploadId`
12. `--skip-existing`：跳过目的地址已经存在的文件（只适用于`get`，`sync`操作）
13. `-r, --recursive `：回归上传，下载或者移除。
14. `--check-md5`：用于同步文件，比较文件时检验MD5值，默认开启。
15. `--no-check-md5`：同步文件，关闭 MD5检验，只进行大小比较，加快了转化速度，但是可能失去一些更改的文件。
16. `-P, --acl-public`：允许资源匿名下载（对于Object），列表（对于Bucket）
17. `--acl-private`：允许拥有者拥有对象的所有权限（默认）
18. `--acl-grant=PERMISSION:EMAIL or USER_CANONICAL_ID`：通过账户的邮箱或者user ID授予资源的权限，权限包含`read, write, read_acp, write_acp, full_control`
	>对`admin`账户授予对`my_bucket01`资源`full_control`权限
	>`s3cmd setacl s3://my_bucket01 --acl-grant=full_control:admin`

19. `--acl-revoke=PERMISSION:USER_CANONICAL_ID`：取消账户的权限，权限包含`read, write, read_acp, wirte_acp`，用法同选项18
20. `-D NUM, --restore-days=NUM`：存储文件可用的时长（单位：天），只能与`restore`命令一起使用
21. `--delete-removed`：删除远程文件，并不与本地文件关联，与`sync`联用
22. `--no-delete-removed`：不删除远程对象
23. `--delete-after`：有新资源上传后删除与`sync`联用
24. `--max-delete=NUM`：删除不超过NUM个文件与`del`和`sync`联用
25. `--add-destination=ADDITIONAL_DESTINATIONS`：用于并发上传的其他地址
26. `--delete-after-fetch`：在获取远程对象后，将远程对象删除，与`get, sync`联用
27. `-p, --preserve`：保留文件系统属性（模式，所有权，时间戳），`sync`命令默认包含此命令
28. `--no-preserve`：不保留文件系统属性
29. `--exclude=GLOB`：文件名和匹配GLOB路径将同步被排除
30. `--exclude-from=FILE`：从`FILE`中读取用于排除的`GLOBs`
31. `--rexclude=REGEXP`：在`sync`时，通过正则表达式排除文件名和路径
32. `--rexclude-from=FILE`：从`FILE`中读取用于排除的正则表达式
33. `--include=GLOB`：即便先前已经排除被排除了，也能通过匹配的GLOB的文件名和路径包含进来
34. `--include-from=FILE`：通过读取`FILE`的方式获取用于包含的`GLOBs`
35. `--rinclude=REGEXP`：通过正则表达式获取包含的内容
36. `--rinclude-from=FILE`：通过读取`FILE`获取用于包含的正则表达式
37. `--files-from=FILE`：从`FILE`读取源文件名的列表
38. `--region=REGION, --bucket-location=REGION`：设置创建Bucket的区域
39. `--reduced-redundancy, --rr`：存储对象设置存储类型为低冗余存储，与`put, cp, mv`联用
40. `--no-reduced-redundancy, --no-rr`：存储对象设置为非低冗余存储，与`put, cp, mv`联用
41. `--storage-class=CLASS`：设置对象的存储类型（`STANDARD, STANDARD_IA, 或 REDUCED_REDUNDANCY`），与`put, cp, mv`联用
42. `--access-logging-target-prefix=LOG_TARGET_PREFIX`：访问日志的目标前缀为`S3 URI：http://acs.amazonaws.com/groups/s3/LogDelivery`，与`cfmodify, accesslog`命令联用
43. `--no-access-logging`：关闭访问日志，与`cfmodify, accesslog`命令联用
44. `--default-mime-type=DEFAULT_MIME_TYPE`：存储对象默认是`MIME`类型，应用默认是`binary/octet-stream`类型
45. `-M, --guess-mime-type`：通过文件扩展名猜测文件的MIME类型
46. `--no-guess-mime-type`：使用文件的默认类型
47. `--no-mime-magic`：不使用`mime magic`来猜测`MIME`类型
48. `-m MIME/TYPE, --mime-type=MIME/TYPE`：强制使用设置的MIME类型，覆盖`--default-mime-type`和`--guess-mime-type`类型
49. `--add-header=NAME:VALUE`：增加`HTTP`头请求，可以使用多次。比如，使用这个选项可以设置`Expires`或者`Cache-Control`头（或者两者都可以）
50. `--remove-header=NAME`：移除已有的`HTTP`头
51. `--server-side-encryption`：上传对象时，采用服务端加密，与`put, sync, cp, modify`联用
52. `--server-side-encryption-kms-id=KMS_KEY`：上传对象时，指定 `key id`给服务端，服务端通过`KWS`进行加密，与`put, sync, cp, modify`联用
53. `--encoding=ENCODING`：覆盖自动检测终端和文件系统编码（字符集），自动检测终端：UTF-8
54. `--disable-multipart`：取消文件大小比`--multipart-chunk-size-mb`大的分段上传，即取消分段上传
55. `--multipart-chunk-size-mb=SIZE`：分段上传块的大小，大于`SIZE`（单位：M）的部分会自动采用多线程上传，默认大小是`15MB`，块大小：最小`5MB`，最大`5GB`
56. `--list-md5`：在Bucket列表中包含`MD5`校验，只适用于`ls`命令
57. `-H, --human-readable-sizes`：打印出可读的形式（例如，`1234`显示为`1kB`）
58. `--ws-index=WEBSITE_INDEX`：`index-document`的名称，只适用于`ws-create`命令
59. `--ws-error=WEBSITE_ERROR`：`error-document`的名称，只适用于`ws-create`命令
60. `--expiry-date=EXPIRY_DATE`：标示到期规则何时生效，与`expire`联用
61. `--expiry-days=EXPIRY_DAYS`：标示对象创建后，到期规则生效的天数
62. `--expiry-prefix=EXPIRY_PREFIX`：用来指定一个或多个对象适用该到期规则，只适用于`expire`命令
63. `--progress`：显示进度表（在TTY上默认显示）
64. `--no-progress`：不显示进度（在non-TTY上默认不显示）
65. `--enable`：启用已有的`CloudFront` ，只适用于`cfmodify`命令
66. `--disable`：关闭已有的`CloudFront` ，只适用于`cfmodify`命令
67. `--cf-invalidate`：上传文件`CloudFront`服务不可用
68. `--cf-invalidate-default-index`：当使用自定义的原始文件和S3的静态网站，默认的index文件无效。
69. `--cf-no-invalidate-default-index-root`：当使用自定义的原始文件和S3的静态网站，默认的index文件路径仍然生效。
70. `--cf-add-cname=CNAME`：增加已有的`CNAME`到`CloudFront`，只适用于`cfcreate, cfmodify`命令
71. `--cf-remove-cname=CNAME`：从`CloudFront`移除`CNAME`，只适用于`cfmodify`命令
72. `--cf-comment=COMMENT`：对于一个给定的`CloudFront`设置评论
73. `--cf-default-root-object=DEFAULT_ROOT_OBJECT`：当URL中为指定对象时，设置默认的root对象用于返回。使用相关路径。比如，用`default/index.html`代替`/default/index.html`或者`s3://bucket/default/index.html`，只适用于`cfcreate， cfmodify`命令
74. `-v, --verbose`：输出启用显示详细信息
75. `-d, --debug`：启用调试输出，会列出调试信息
76. `--version`：显示**s3cmd**版本信息
77. `-F, --follow-symlinks`：当他们是规则文件时，跟踪链接
78. `--cache-file=FILE`：包含本地源的MD5值缓存文件
79. `-q, --quiet`：是标准输出时，不输出信息
80. `--ca-certs=CA_CERTS_FILE`：**SSL CA**证书的路径
81. `--check-certificate`：查看**SSL**证书是否有效
82. `--no-check-certificate`：不检查**SSL**证书的有效性
83. `--check-hostname`：查看**SSL**证书的`hostname`是否有效
84. `--no-check-hostname`：不检查**SSL**证书的`hostname`的有效性
85. `--signature-v2`：使用AWS签名版本2代替最新的签名版本
86. `--limit-rate=LIMITRATE`：限制上传或者下载速度（单位：bytes/s）,支持`k, m`后缀
87. `--requester-pays`：对于操作 ，设置申请方付款标志
88. `-l, --long-listing`：产生长列表，与`ls`联用
89. `--stop-on-error`：如果在传输中出现错误，则停止传输
90. `--content-disposition=CONTENT_DISPOSITION`：为签名的**URL**提供`Content-Disposition`，例如，`"inline; filename=myvideo.mp4"`
91. `--content-type=CONTENT_TYPE`：为签名的**URL**提供`Content-Type`，例如，`"video/mp4"`
92. `-n, --dry-run `：只显示应该怎样上传或下载，但实际上并没有做。仍可以进行S3请求得到Bucket列表等信息，只适用于文件传输命令
93. `-s, --ssl`：使用`HTTPS`连接S3
94. `--no-ssl`：不使用`HTTPS`连接S3
#ceph #s3
